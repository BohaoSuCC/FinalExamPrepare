% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=25mm, left=30mm, right=30mm, bottom=25mm,
heightrounded]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Guidance},
  pdfauthor={BohaoSu},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Guidance}
\author{BohaoSu}
\date{2023-12-13}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\hypertarget{initial-project-scope}{%
\section{Initial project scope}\label{initial-project-scope}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(broom)}
\FunctionTok{library}\NormalTok{(car)}
\FunctionTok{library}\NormalTok{(classInt)}
\FunctionTok{library}\NormalTok{(corrplot)}
\FunctionTok{library}\NormalTok{(crosstalk)}
\FunctionTok{library}\NormalTok{(DiagrammeR)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(fs)}
\FunctionTok{library}\NormalTok{(geojsonio)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(ggmap)}
\FunctionTok{library}\NormalTok{(here)}
\FunctionTok{library}\NormalTok{(janitor)}
\FunctionTok{library}\NormalTok{(maptools)}
\FunctionTok{library}\NormalTok{(mapview)}
\FunctionTok{library}\NormalTok{(OpenStreetMap)}
\FunctionTok{library}\NormalTok{(patchwork)}
\FunctionTok{library}\NormalTok{(plotly)}
\FunctionTok{library}\NormalTok{(RColorBrewer)}
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(rJava)}
\FunctionTok{library}\NormalTok{(rgdal)}
\FunctionTok{library}\NormalTok{(RSQLite)}
\FunctionTok{library}\NormalTok{(rgeos)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{library}\NormalTok{(spatstat)}
\FunctionTok{library}\NormalTok{(spdep)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(tmap)}
\FunctionTok{library}\NormalTok{(tmaptools)}
\end{Highlighting}
\end{Shaded}

\hypertarget{research-question}{%
\subsection{Research Question:}\label{research-question}}

\begin{itemize}
\tightlist
\item
  What are the factors that might lead to xxxxxxxxxxxxx scores in the
  xxxxxxxx city?
\end{itemize}

\hypertarget{hypothesis}{%
\subsection{Hypothesis:}\label{hypothesis}}

\begin{itemize}
\tightlist
\item
  Null hypothesis: There is complete spatial randomness. No statistical
  significance exists in a set of given observations. There is no
  pattern - i.e.~complete spatial randomness - in our data. There is no
  relationship between exam scores and other observed variables across
  London.
\item
  Alternative hypothesis: Our data does exhibit a pattern.
\end{itemize}

\hypertarget{methodology}{%
\subsection{Methodology:}\label{methodology}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The first step is always cleaning and pre-processing data, which is
  the foundation for any kinds of analysis and modelling.
\item
  Exploration Data Analysis(histograms and Q-Q plots for statistical
  information, KDE for spatial distribution, DBSCAN for spatial
  clustering, etc.) need to be done both for non-spatial and spatial
  fields. This step would clarify the simple relationship and some
  features inside the data.
\item
  Based on research purpose, the regression model also needs two
  important prerequisite to guarantee its adaptability and rationality.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  The first one is ``The xxxxxx's happening does have summarizable and
  discernible spatial distribution characteristics and spatial
  patterns.'' This indicates whether a spatial analysis rather than
  purely quantitative analysis should be utilized to address the
  research question. Hence, Spatial patterns analysis like KDE or DBSCAN
  should be operated to check whether there is random occurrences for
  the xxxxxxxxxxx or not. If the result is complete random distribution,
  I'll just do the basic quantitative analysis based on the non-spatial
  data.
\item
  The second one is ``Spatial location information does play as a
  crucial and indispensable variable when building regression models.''
  This means which regression model should be utilized to analysis and
  predict the xxxxxxx. I suppose spatial autocorrelation methods should
  be used to examine the adaptability of Tobler's
  Law.\citep{tobler_computer_1970} If there is no evidence showing
  geographical elements does affect the dependant variables
  distribution, then linear regression model or polynomial regression
  model should be the options. Otherwise, we should consider spatial
  information and select spatial regression models like spatial lag and
  spatial error models or geographically weighted regression models.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  Afterwards, some advanced filtering or merging should be operated
  based on the ESDA, after which some cleansed columns and features
  could be extracted from the raw data and regarded as the independent
  variables for regression model to test the hypothesis. The variables
  selection process should also take some background context and
  research purpose into consideration.
\item
  Then, modelling part should be emphasized on which model should be
  selected. Regression Model selection will refer to all above previous
  analysis and prerequisites. After establishing a baseline model, the
  focus shifts to evaluating and refining this model. This involves
  comparing the baseline model's performance against the spatial models,
  using metrics such as R-squared, AIC, or RMSE for validation and
  visualization. This process of model selection and refinement is
  central to achieving reliable and meaningful insights from the spatial
  analysis.
\item
  At the End, all results and features would be generalized and
  summarized, and a primary research conclusion will be drawn towards
  the initial question.
\end{enumerate}

\hypertarget{potential-limitation-of-data-and-methods}{%
\subsection{Potential Limitation of data and
methods}\label{potential-limitation-of-data-and-methods}}

\hypertarget{data-limitation}{%
\subsubsection{Data Limitation}\label{data-limitation}}

\begin{itemize}
\item
  Issues with Spatial Scale: The spatial scale of the data (e.g.,
  geographic extent and resolution) can affect the analysis outcomes.
  Different spatial scales may reveal different patterns and
  relationships.
\item
  Data Quality and Completeness: The dataset may have missing or
  inaccurate data, leading to biased analysis results. And we will also
  drop part of the data due to some NAs or administrative boundaries,
  which will also impact on dataset's completeness.
\end{itemize}

\hypertarget{methods-limitation}{%
\subsubsection{Methods Limitation}\label{methods-limitation}}

\begin{itemize}
\item
  Non-independence of Spatial Data: Traditional non-spatial regression
  models often assume independence between observations, which may not
  hold true for spatial data. Spatial dependence between neighboring
  locations can impact the accuracy of the model.
\item
  Spatial Autocorrelation in Residuals: In many regression models,
  spatial autocorrelation in residuals is considered a serious
  violation. If residuals from the model show spatial clustering, it
  might indicate that key variables are missing from the model.
\end{itemize}

\hypertarget{rmd-environment-configuration}{%
\subsection{RMD environment
configuration}\label{rmd-environment-configuration}}

Before the specific illustration and analysis procedure, some
environment configuration should be down to guarantee this .RMD file's
robust on various platform and devices.

\begin{itemize}
\tightlist
\item
  Download .bib and .csl file remotely for reference
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# download reference.bib remotely from my github}
\FunctionTok{download.file}\NormalTok{(}\StringTok{"https://github.com/xxxxxxx.bib"}\NormalTok{, }
              \AttributeTok{destfile=}\NormalTok{here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"reference.bib"}\NormalTok{))}

\CommentTok{\# download reference.bib remotely from my github}
\FunctionTok{download.file}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/BohaoSuCC/CASA0005BohaoSu/main/ucl{-}institute{-}of{-}education{-}harvard.csl"}\NormalTok{, }
              \AttributeTok{destfile=}\NormalTok{here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"ucl{-}institute{-}of{-}education{-}harvard.csl"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Create Data Folder for Loading and Saving Data
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create the folder storing data for a better robust}
\NormalTok{folder\_name }\OtherTok{\textless{}{-}} \StringTok{"Data"}

\CommentTok{\# get the root dir}
\NormalTok{root\_dir }\OtherTok{\textless{}{-}}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}

\CommentTok{\# construct the full path}
\NormalTok{folder\_path }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(root\_dir, folder\_name)}

\CommentTok{\# check if the folder already exists}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{dir.exists}\NormalTok{(folder\_path)) \{}
  \FunctionTok{dir.create}\NormalTok{(folder\_path)}
  \FunctionTok{message}\NormalTok{(}\StringTok{"Folder \textquotesingle{}"}\NormalTok{, folder\_name, }\StringTok{"\textquotesingle{} created at "}\NormalTok{, folder\_path)}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
  \FunctionTok{message}\NormalTok{(}\StringTok{"Folder \textquotesingle{}"}\NormalTok{, folder\_name, }\StringTok{"\textquotesingle{} already exists at "}\NormalTok{, folder\_path)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-introduction}{%
\section{Data Introduction}\label{data-introduction}}

\hypertarget{downloading-unzipping-and-loading-the-data}{%
\subsection{Downloading, Unzipping and loading the
data}\label{downloading-unzipping-and-loading-the-data}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Downloading the relating files and save and unzip it.}
\FunctionTok{download.file}\NormalTok{(}\StringTok{"https://data.london.gov.uk/download/statistical{-}gis{-}boundary{-}files{-}london/9ba8c833{-}6370{-}4b11{-}abdc{-}314aa020d5e0/statistical{-}gis{-}boundaries{-}london.zip"}\NormalTok{, }
              \AttributeTok{destfile=}\NormalTok{here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"Data"}\NormalTok{,}\StringTok{"statistical{-}gis{-}boundaries{-}london.zip"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{listfiles}\OtherTok{\textless{}{-}}\FunctionTok{dir\_info}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"Data"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(path, }\StringTok{"london.zip"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(path)}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{()}\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\#print out the .gz file}
  \FunctionTok{print}\NormalTok{()}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.character}\NormalTok{()}\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  utils}\SpecialCharTok{::}\FunctionTok{unzip}\NormalTok{(}\AttributeTok{exdir=}\NormalTok{here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"Data"}\NormalTok{))}

\CommentTok{\# reading the shp}
\NormalTok{Londonwards}\OtherTok{\textless{}{-}}\NormalTok{fs}\SpecialCharTok{::}\FunctionTok{dir\_info}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"Data"}\NormalTok{, }
                                 \StringTok{"statistical{-}gis{-}boundaries{-}london"}\NormalTok{, }
                                 \StringTok{"ESRI"}\NormalTok{))}\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\#$ means exact match}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(path, }
                           \StringTok{"London\_Ward\_CityMerged.shp$"}\NormalTok{))}\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(path)}\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{pull}\NormalTok{()}\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\#read in the file in}
\NormalTok{  sf}\SpecialCharTok{::}\FunctionTok{st\_read}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Reading the csv and Add na argument to make sure csv\textquotesingle{}s robust}
\CommentTok{\# replace all the nas as " "}
\NormalTok{data\_test }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"Data"}\NormalTok{,}\StringTok{"Evictions\_20231212.csv"}\NormalTok{), }\AttributeTok{na=}\FunctionTok{c}\NormalTok{(}\StringTok{" "}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{LondonWardProfiles }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://data.london.gov.uk/download/ward{-}profiles{-}and{-}atlas/772d2d64{-}e8c6{-}46cb{-}86f9{-}e52b4c7851bc/ward{-}profiles{-}excel{-}version.csv"}\NormalTok{, }
                               \AttributeTok{col\_names =} \ConstantTok{TRUE}\NormalTok{, }
                               \AttributeTok{locale =} \FunctionTok{locale}\NormalTok{(}\AttributeTok{encoding =} \StringTok{\textquotesingle{}UTF{-}8\textquotesingle{}}\NormalTok{))}


\CommentTok{\#Reading the shp file}
\NormalTok{community\_areas }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"Data"}\NormalTok{,}\StringTok{"geo\_export\_7fdf694c{-}62dd{-}4de4{-}8f17{-}0b5ca2408993.shp"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-description}{%
\subsection{Data Description}\label{data-description}}

\begin{itemize}
\tightlist
\item
  The dataset is mainly about xxxxxxxxxxxx, containing xxxxxxxxxxxxxxx
  in New York city. It is collected by xxxxxx and xxxx through xxxxx and
  published in the \href{https://www.openai.com/}{xxxx's website}.
\item
  Another data is xxxxx.shp, containing geographical information
  features about xxxxxxxx in xxxx city, which is published by xxxxx and
  can be public accessed through \href{https://www.openai.com/}{xxxx's
  website}.
\end{itemize}

\hypertarget{na-values}{%
\subsection{NA values}\label{na-values}}

In the dataset, the NA values could probably mean the missed data,
unrecorded observations, inapplicable data points, etc.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#check all of the columns have been read in correctly}
\NormalTok{Column\_type\_list }\OtherTok{\textless{}{-}}\NormalTok{ evictions\_points }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise\_all}\NormalTok{(class) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\FunctionTok{everything}\NormalTok{(), }
               \AttributeTok{names\_to=}\StringTok{"All\_variables"}\NormalTok{, }
               \AttributeTok{values\_to=}\StringTok{"Variable\_class"}\NormalTok{)}
\NormalTok{total\_rows }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(evictions\_points)}

\CommentTok{\#get the na values proportion of each column}
\NormalTok{Column\_NA\_ratio\_list }\OtherTok{\textless{}{-}}\NormalTok{ evictions\_points }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise\_all}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(.))}\SpecialCharTok{/}\NormalTok{total\_rows) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\FunctionTok{everything}\NormalTok{(), }
               \AttributeTok{names\_to=}\StringTok{"All\_variables"}\NormalTok{, }
               \AttributeTok{values\_to=}\StringTok{"Variable\_NA\_ratio"}\NormalTok{)}

\CommentTok{\# check the CRS and any error within spatial data}
\FunctionTok{st\_geometry}\NormalTok{(BoroughMap)}

\NormalTok{Column\_type\_list}
\NormalTok{Column\_NA\_count\_list}
\end{Highlighting}
\end{Shaded}

From the statistical chart we could see there are totally xxxx
rows(observations) containing NAs values. Technically, I don't think it
is a high rate and these NA values could have a significant impact on my
analysis.

Also, I am going to consider how to deal with those NA values with
different solutions according to each column's role during my analysis.
Anyway, the specific solutions to these NA values should align with
research question and analysis requirement, so the detailed Data
processing would be demonstrated in Data Cleaning and Processing.

\hypertarget{accuracy-and-biasing}{%
\subsection{Accuracy and Biasing}\label{accuracy-and-biasing}}

\begin{itemize}
\tightlist
\item
  Due to the absence of some accuracy information such as measurement
  errors, data validation processes, etc, I will focus on the biases of
  the data. According to the description on the website
  \href{https://www.openai.com/}{xxxx's website}, the purpose of
  collecting these data is mainly to xxxxxxxxxxxxxxxxxxxx, which might
  bring about the biases of not xxxxxxxxxxxxxxxxxxxxxxxxx. However, I do
  not think this kind of biases will bring obvious and significant
  impact on analysis results and conclusions, even though the data
  collection methods do have limitation which I would elaborate
  detailedly afterwards.
\end{itemize}

\hypertarget{coordinate-reference-system-crs}{%
\subsection{Coordinate Reference System
(CRS)}\label{coordinate-reference-system-crs}}

\begin{itemize}
\tightlist
\item
  Explain the coordinate reference system used in the data, including
  its type (such as geographic or projected coordinate system) and
  specific name (like WGS 84, UTM, etc.).
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# transform the non{-}spatial data into spatial data based on columns\textquotesingle{}Longitude\textquotesingle{}\textquotesingle{}Latitude\textquotesingle{}}
\NormalTok{Airbnb }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"listings.csv"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_as\_sf}\NormalTok{(., }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"longitude"}\NormalTok{, }\StringTok{"latitude"}\NormalTok{), }
                   \AttributeTok{crs =} \DecValTok{4326}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{st\_transform}\NormalTok{(., }\DecValTok{27700}\NormalTok{)}\SpecialCharTok{\%\textgreater{}\%}
    \CommentTok{\# After, do some relavant filter for the useful info}
    \FunctionTok{filter}\NormalTok{(room\_type }\SpecialCharTok{==} \StringTok{\textquotesingle{}Entire home/apt\textquotesingle{}} \SpecialCharTok{\&}\NormalTok{ availability\_365 }\SpecialCharTok{==}\StringTok{\textquotesingle{}365\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Transform the CRS}
\NormalTok{sf\_DATA\_transformed }\OtherTok{\textless{}{-}} \FunctionTok{st\_transform}\NormalTok{(sf\_DATA, }\AttributeTok{crs =} \DecValTok{32650}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  In this analysis, we have selected the {[}specify CRS, e.g., WGS 84,
  EPSG:4326{]} as our Coordinate Reference System (CRS). This CRS aligns
  well with our study's geographic scope that includes {[}mention the
  geographical extent, e.g., multiple countries, global analysis,
  etc.{]}.
\item
  Moreover, the impact of using {[}specify CRS{]} on my spatial
  analysis, especially in GWR where a spatial weight matrix really
  matters, is significant. And that requires distance measurement should
  be calculated, demonstrated and visualized precisely. Using projected
  CRS, I believe, should be a better choice for visualization,
  especially for some local-scale analysis and maps.
\end{itemize}

\hypertarget{data-cleaning-and-processing}{%
\section{Data Cleaning and
Processing}\label{data-cleaning-and-processing}}

\hypertarget{dealing-with-nas-in-spatial-and-non-spatial-dataset}{%
\subsection{Dealing with NAs in spatial and non-spatial
dataset}\label{dealing-with-nas-in-spatial-and-non-spatial-dataset}}

Some columns, such as xxxxxxxxxx, are extremely important that we
couldn't extract any useful information if there are NA values. Besides,
its high accuracy makes it harder to fill missing values, which leads us
to nothing else but to drop them. Some of the columns, such like xxxx
and some categorical data, we also could classify all the NA values as a
new category. Some columns like xxxxxxxxxx, we could assume, based on
the context of the study and common sense, that the missing values are
0. Although this approach may introduce some degree of inaccuracy, it is
considered a practical solution since the proportion of NA values in
these columns is very high. Therefore, dropping these columns outright
would be an unwise decision.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# na.omit(): 从数据中删除含有 NA 的行。}
\CommentTok{\# 参数：object（数据对象）。}
\CommentTok{\# 默认参数：无默认参数。}
\FunctionTok{library}\NormalTok{(dplyr)}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}} \FunctionTok{na.omit}\NormalTok{(DATA)}

\CommentTok{\# dplyr::filter(): 删除特定条件下的行。}
\CommentTok{\# 参数：.DATA（数据框），...（条件表达式）。}
\CommentTok{\# 默认参数：无默认参数。}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(COLUMN\_name))}

\CommentTok{\# tidyr::replace\_na(): 用特定值替换 NA。}
\CommentTok{\# 参数：DATA（数据框），replace（用于替换的值）。}
\CommentTok{\# 默认参数：无默认参数。}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{replace\_na}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{COLUMN =}\NormalTok{ replacement\_value))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# na.omit(): 从数据中删除含有 NA 的行。}
\CommentTok{\# 参数：object（数据对象）。}
\CommentTok{\# 默认参数：无默认参数。}
\FunctionTok{library}\NormalTok{(dplyr)}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}} \FunctionTok{na.omit}\NormalTok{(DATA)}

\CommentTok{\# dplyr::filter(): 删除特定条件下的行。}
\CommentTok{\# 参数：.DATA（数据框），...（条件表达式）。}
\CommentTok{\# 默认参数：无默认参数。}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(COLUMN\_name))}

\CommentTok{\# tidyr::replace\_na(): 用特定值替换 NA。}
\CommentTok{\# 参数：DATA（数据框），replace（用于替换的值）。}
\CommentTok{\# 默认参数：无默认参数。}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{replace\_na}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{COLUMN =}\NormalTok{ replacement\_value))}
\end{Highlighting}
\end{Shaded}

\hypertarget{converting-datatype}{%
\subsection{Converting Datatype}\label{converting-datatype}}

And we will also convert some columns into specific datatype for more
covenient processing.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# as.numeric(): 将数据转换为数值类型。}
\CommentTok{\# 参数：x（输入数据）。}
\CommentTok{\# 默认参数：无默认参数。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{COLUMN }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{COLUMN)}

\CommentTok{\#as.character(): 将数据转换为字符类型。}
\CommentTok{\#参数：x（输入数据）。}
\CommentTok{\#默认参数：无默认参数。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{COLUMN }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{COLUMN)}

\CommentTok{\#as.Date(): 将数据转换为日期类型。}
\CommentTok{\#参数：x（输入数据），format（日期格式）。}
\CommentTok{\#默认参数：format = "\%Y{-}\%m{-}\%d"。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{date\_COLUMN }\OtherTok{\textless{}{-}} \FunctionTok{as.Date}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{date\_COLUMN, }\AttributeTok{format =} \StringTok{"\%Y{-}\%m{-}\%d"}\NormalTok{)}

\NormalTok{DATA }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{COLUMN =} \FunctionTok{str\_replace\_all}\NormalTok{(COLUMN, }\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{$"}\NormalTok{, }\StringTok{""}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# remove dollar sign}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{COLUMN =} \FunctionTok{str\_replace\_all}\NormalTok{(COLUMN, }\StringTok{","}\NormalTok{, }\StringTok{""}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# remove the comma}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{COLUMN =} \FunctionTok{as.numeric}\NormalTok{(COLUMN))  }
\end{Highlighting}
\end{Shaded}

\hypertarget{delete-or-filter-outliers}{%
\subsection{Delete or Filter outliers}\label{delete-or-filter-outliers}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#select all spatial feature with the city boundary and transorm its CRS}
\NormalTok{BoroughMap }\OtherTok{\textless{}{-}}\NormalTok{ LondonBoroughs }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(GSS\_CODE, }\StringTok{"\^{}E09"}\NormalTok{))}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_transform}\NormalTok{(., }\DecValTok{27700}\NormalTok{)}

\CommentTok{\#delete specific rows by filter and some arguments}

\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(COLUMN }\SpecialCharTok{\textgreater{}=}\NormalTok{ lower\_limit, COLUMN }\SpecialCharTok{\textless{}=}\NormalTok{ upper\_limit)}

\CommentTok{\# only remain points which inside the boundary}
\NormalTok{BluePlaquesSub }\OtherTok{\textless{}{-}}\NormalTok{ BluePlaques[BoroughMap, , op}\OtherTok{=}\NormalTok{st\_within]}
\CommentTok{\# to identify points completely within the borough outline, or a variety of other options such as st\_overlaps, st\_touches, st\_contains, st\_disjoint}

\CommentTok{\# plot the map to check to see that they\textquotesingle{}ve been removed}
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"plot"}\NormalTok{)}
\FunctionTok{tm\_shape}\NormalTok{(BoroughMap) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{col =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
\FunctionTok{tm\_shape}\NormalTok{(BluePlaquesSub) }\SpecialCharTok{+}
  \FunctionTok{tm\_dots}\NormalTok{(}\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-format-normalization-ux6570ux636eux683cux5f0fux6807ux51c6ux5316}{%
\subsection{Data Format Normalization
数据格式标准化}\label{data-format-normalization-ux6570ux636eux683cux5f0fux6807ux51c6ux5316}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#tolower(): 将文本转换为小写。}
\CommentTok{\#参数：x（输入文本）。}
\CommentTok{\#默认参数：无默认参数。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{column }\OtherTok{\textless{}{-}} \FunctionTok{tolower}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{column)}

\CommentTok{\#toupper(): 将文本转换为大写。}
\CommentTok{\#参数：x（输入文本）。}
\CommentTok{\#默认参数：无默认参数。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{column }\OtherTok{\textless{}{-}} \FunctionTok{toupper}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{column)}

\CommentTok{\#str\_trim(): 去除文本两侧的空格（stringr 包）。}
\CommentTok{\#参数：string（输入文本），side（修剪的方向）。}
\CommentTok{\#默认参数：side = "both"。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{column }\OtherTok{\textless{}{-}} \FunctionTok{str\_trim}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{column)}
\end{Highlighting}
\end{Shaded}

\hypertarget{dealing-with-repetitive-or-unique-rows}{%
\subsection{Dealing with Repetitive or Unique
rows}\label{dealing-with-repetitive-or-unique-rows}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make sure there is no more repetitive rows in the data}
\NormalTok{BluePlaques }\OtherTok{\textless{}{-}} \FunctionTok{distinct}\NormalTok{(BluePlaques)}

\CommentTok{\#duplicated(): 检测重复行。}
\CommentTok{\#参数：x（输入数据）。}
\CommentTok{\#默认参数：无默认参数。}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ DATA[}\SpecialCharTok{!}\FunctionTok{duplicated}\NormalTok{(DATA), ]}

\CommentTok{\#unique(): 获取唯一行。}
\CommentTok{\#参数：x（输入数据）。}
\CommentTok{\#默认参数：无默认参数。}
\NormalTok{DATA\_cleaned }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(DATA)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-integration-ux6570ux636eux6574ux5408}{%
\subsection{DATA Integration
数据整合}\label{data-integration-ux6570ux636eux6574ux5408}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 两个non{-}spatial数据之间，还有inner\_join,right\_join,full\_join}
\NormalTok{DATA\_combined }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(DATA1, DATA2, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}SAME\_COLUMN\_NAME\textquotesingle{}}\OtherTok{=}\StringTok{\textquotesingle{}SAME\_COLUMN\_NAME\textquotesingle{}}\NormalTok{))}

\CommentTok{\# spatial data join。 Argument could be }
\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{st\_join}\NormalTok{(x, y, }\AttributeTok{op =}\NormalTok{ st\_intersects)}

\CommentTok{\#plot the Pointsdata in the area}
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"plot"}\NormalTok{)}
\FunctionTok{tm\_shape}\NormalTok{(BoroughMap) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{col =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
\FunctionTok{tm\_shape}\NormalTok{(Pointsdata) }\SpecialCharTok{+}
  \FunctionTok{tm\_dots}\NormalTok{(}\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# select by attribute}
\NormalTok{studyarea\_window }\OtherTok{\textless{}{-}}\NormalTok{ BoroughMap }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(GSS\_CODE, }\StringTok{"\^{}E09"}\NormalTok{))}

\CommentTok{\#Check to see that the correct borough has been pulled out}
\FunctionTok{tm\_shape}\NormalTok{(studyarea\_window) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{col =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)}

\CommentTok{\#clip the data to our single borough}
\NormalTok{Pointsdata }\OtherTok{\textless{}{-}}\NormalTok{ Pointsdata[studyarea\_window,]}
\CommentTok{\#check that it\textquotesingle{}s worked}
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"plot"}\NormalTok{)}

\FunctionTok{tm\_shape}\NormalTok{(studyarea\_window) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{col =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
\FunctionTok{tm\_shape}\NormalTok{(Pointsdata) }\SpecialCharTok{+}
  \FunctionTok{tm\_dots}\NormalTok{(}\AttributeTok{col =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# select by attribute}
\NormalTok{studyarea\_window }\OtherTok{\textless{}{-}}\NormalTok{ BoroughMap }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(GSS\_CODE, }\StringTok{"\^{}E09"}\NormalTok{))}

\CommentTok{\#Check to see that the correct borough has been pulled out}
\FunctionTok{tm\_shape}\NormalTok{(studyarea\_window) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{col =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)}

\CommentTok{\#create a sp object}
\NormalTok{BluePlaquesSub}\OtherTok{\textless{}{-}}\NormalTok{ BluePlaquesSub }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as}\NormalTok{(., }\StringTok{\textquotesingle{}Spatial\textquotesingle{}}\NormalTok{)}

\CommentTok{\# create the window from above studyarea\_window}
\NormalTok{window }\OtherTok{\textless{}{-}} \FunctionTok{as.owin}\NormalTok{(studyarea\_window)}
\FunctionTok{plot}\NormalTok{(window)}

\CommentTok{\#create a ppp object}
\NormalTok{Pointsdata.ppp }\OtherTok{\textless{}{-}} \FunctionTok{ppp}\NormalTok{(}\AttributeTok{x=}\NormalTok{BluePlaquesSub}\SpecialCharTok{$}\NormalTok{Longitude,}
                          \AttributeTok{y=}\NormalTok{BluePlaquesSub}\SpecialCharTok{$}\NormalTok{Latitude,}
                          \AttributeTok{window=}\NormalTok{window)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exploration-spatial-data-analysis-esda}{%
\section{Exploration Spatial Data Analysis
(ESDA)}\label{exploration-spatial-data-analysis-esda}}

Exploration Spatial Data Analysis (ESDA) plays an significant role in
spatial regression modeling, primarily focusing on three key aspects. -
First part contains acquiring statistical characteristics and
distribution patterns of all non-spatial data, providing a solid
foundation for selecting relevant independent variables for the model.
This step is crucial for understanding the underlying structure and
relationships within the data. - Second part involves cluster analysis
to ascertain if the data exhibits spatial clustering, indicating
non-random distribution across the space. This analysis verifies one of
the prerequisites for spatial regression modeling, ensuring the data's
suitability for such analysis.

\begin{itemize}
\tightlist
\item
  Another essential prerequisite will be checked in part3, which is the
  impact of geographical spatial differences on certain dependent
  variables in spatial data. This is accomplished by conducting spatial
  autocorrelation analysis, which helps to confirm if spatial factors
  significantly influence the variables in question, thereby validating
  the use of spatial regression techniques.
\end{itemize}

\hypertarget{distribution-and-coorelationship}{%
\subsection{Distribution and
coorelationship}\label{distribution-and-coorelationship}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_test}\SpecialCharTok{$}\NormalTok{Latitude }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(data\_test}\SpecialCharTok{$}\NormalTok{Latitude)}

\NormalTok{clean\_data }\OtherTok{\textless{}{-}}\NormalTok{ data\_test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter\_all}\NormalTok{(}\FunctionTok{all\_vars}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(.)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(clean\_data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Latitude)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.01}\NormalTok{, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 绘制var1的直方图}
\FunctionTok{ggplot}\NormalTok{(data\_test, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Latitude)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{)}

\CommentTok{\# 绘制var1和var2之间的散点图}
\FunctionTok{ggplot}\NormalTok{(data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ var1, }\AttributeTok{y =}\NormalTok{ var2)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}

\CommentTok{\# 箱子图{-}假设你的数据框架是data，列名为num\_var}
\FunctionTok{ggplot}\NormalTok{(data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ num\_var)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{fill =} \StringTok{"lightblue"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\CommentTok{\# 条形图（Bar charts）条形图用于显示分类变量的频率。}
\FunctionTok{ggplot}\NormalTok{(data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ cat\_var)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"lightgreen"}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkgreen"}\NormalTok{)}

\CommentTok{\# 计算cormatrix{-}{-}{-}{-}假设你的数据框架是data，选择其中的几个数值型列}
\NormalTok{numeric\_data }\OtherTok{\textless{}{-}}\NormalTok{ data[}\FunctionTok{c}\NormalTok{(}\StringTok{"num\_var1"}\NormalTok{, }\StringTok{"num\_var2"}\NormalTok{, }\StringTok{"num\_var3"}\NormalTok{)]}
\CommentTok{\# 计算相关系数矩阵}
\NormalTok{cor\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(numeric\_data)}
\CommentTok{\# 绘制相关系数矩阵}
\FunctionTok{corrplot}\NormalTok{(cor\_matrix, }\AttributeTok{method =} \StringTok{"circle"}\NormalTok{)}
\CommentTok{\#这段代码首先计算了numeric\_data中数值型变量的相关系数矩阵，}
\CommentTok{\#然后使用corrplot()函数绘制出相关系数矩阵。}
\CommentTok{\#method = "circle"表示使用圆圈的方式来表示相关系数的大小和方向。}
\CommentTok{\#"circle"：使用圆圈，圆圈越大，相关性越强；颜色通常用来表示正负相关。}
\CommentTok{\#"square"：与 "circle" 类似，但使用正方形来表示相关系数。}
\CommentTok{\#"ellipse"：使用椭圆形状，椭圆的形状和方向表示相关性的强度和方向。}
\CommentTok{\#"number"：直接在每个格子中显示相关系数的数值。}
\CommentTok{\#"shade"：通过阴影深浅来表示相关系数的大小，通常不显示相关系数的具体数值。}
\CommentTok{\#"color"：仅通过颜色来表示相关系数的大小和方向，类似于热图。}
\CommentTok{\#"pie"：使用饼图来表示相关系数，饼图的大小和填充比例反映相关性的强度和方向。}
\end{Highlighting}
\end{Shaded}

\hypertarget{several-histograms-ux591aux4e2aux56feux5408ux5e76}{%
\subsection{Several Histograms
多个图合并}\label{several-histograms-ux591aux4e2aux56feux5408ux5e76}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(data\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Court Index Number"        "Docket Number"            
##  [3] "Eviction Address"          "Eviction Apartment Number"
##  [5] "Executed Date"             "Marshal First Name"       
##  [7] "Marshal Last Name"         "Residential/Commercial"   
##  [9] "BOROUGH"                   "Eviction Postcode"        
## [11] "Ejectment"                 "Eviction/Legal Possession"
## [13] "Latitude"                  "Longitude"                
## [15] "Community Board"           "Council District"         
## [17] "Census Tract"              "BIN"                      
## [19] "BBL"                       "NTA"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{columns\_name\_datatest }\OtherTok{\textless{}{-}} \FunctionTok{names}\NormalTok{(data\_test)[}\FunctionTok{c}\NormalTok{(}\DecValTok{13}\NormalTok{,}\DecValTok{14}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{16}\NormalTok{)]}

\CommentTok{\# create a new list to save every histogram}
\NormalTok{plots\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}

\CommentTok{\#ggplot(clean\_data, aes(x = Latitude)) + }
  \CommentTok{\#geom\_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha=0.5)}

\CommentTok{\# create a histogram towards every column and add it into the plot list}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) \{}
\NormalTok{  column\_name }\OtherTok{\textless{}{-}}\NormalTok{ columns\_name\_datatest[i]}
\NormalTok{  pic }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(data\_test, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \SpecialCharTok{!!}\FunctionTok{sym}\NormalTok{(column\_name))) }\SpecialCharTok{+} 
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{fill =} \StringTok{"lightblue"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{ggtitle}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Histogram of"}\NormalTok{, column\_name)) }\SpecialCharTok{+}   \CommentTok{\#每个图的图名}
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Values of"}\NormalTok{, column\_name)) }\SpecialCharTok{+}  \CommentTok{\# 设置X轴标题}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"Frequency"}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# 设置Y轴标题为“频率”}
    \FunctionTok{theme}\NormalTok{(}
      \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust=}\FloatTok{0.5}\NormalTok{),  }\CommentTok{\# 设置图表标题字体大小}
      \AttributeTok{axis.title.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{8}\NormalTok{),  }\CommentTok{\# 设置X轴标题字体大小}
      \AttributeTok{axis.title.y =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{8}\NormalTok{)   }\CommentTok{\# 设置Y轴标题字体大小}
\NormalTok{    )}
\NormalTok{  plots\_list[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ pic}
\NormalTok{\}}

\CommentTok{\# using patchwork to combine every histograms into a 2*2 grids}
\NormalTok{combined\_plot }\OtherTok{\textless{}{-}} \FunctionTok{wrap\_plots}\NormalTok{(plots\_list, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{\&} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{hjust=}\FloatTok{0.5}\NormalTok{),}
    \AttributeTok{axis.title.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{8}\NormalTok{),}
    \AttributeTok{axis.title.y =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{8}\NormalTok{)}
\NormalTok{  )}

\NormalTok{combined\_plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{Guidance_files/figure-latex/unnamed-chunk-12-1.pdf}

\hypertarget{spatial-distribution-ux67e5ux770bux7a7aux95f4ux5206ux5e03}{%
\subsection{Spatial Distribution
查看空间分布}\label{spatial-distribution-ux67e5ux770bux7a7aux95f4ux5206ux5e03}}

In order to understand the spatial distribution, I utilized Kernel
Density Estimation (KDE) for its analysis. This method could provide
with an in-depth examination of xxxxxxxxxxxxxxxxxxxx (specific aspect or
feature of the data), enabling a clearer visualization of spatial
concentration and patterns within the study area. The KDE plot is
particularly effective in highlighting areas of high density or
clustering, which is essential for the analysis of
xxxxxxxxxxxxxxxxxxxxxx (specific phenomena or geographic feature). -
From the Heatmaps plot we could see xxxxxxxxxxxxxxxxxxxxxxxxxxx

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Pointsdata.ppp }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{density}\NormalTok{(., }\AttributeTok{sigma=}\DecValTok{500}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  From the KDE (Kernel Density Estimation) plot, we can observe
  xxxxxxxxxxxxxxxxx. This suggests that the distribution of data
  exhibits a trend of xxxxxxxxxxxxxxxxxxxxxxxxxxxxx, which is crucial
  for understanding xxxxxxxxxxxxxxxxxxxxxxx (specific data
  characteristic or geographic feature). Particularly in the region of
  xxxxxxxxxxxxxxxxxxx, this distribution provides key insights into
  xxxxxxxxxxxxxx (a relevant phenomenon or issue).''
\end{itemize}

\hypertarget{spatial-patterns-ux67e5ux770bux7a7aux95f4ux6a21ux5f0fux5982ux805aux96c6ux79bbux6563}{%
\subsection{Spatial Patterns
查看空间模式（如聚集、离散）}\label{spatial-patterns-ux67e5ux770bux7a7aux95f4ux6a21ux5f0fux5982ux805aux96c6ux79bbux6563}}

In spatial data analysis, identifying whether patterns are clustered or
dispersed is crucial, which could also examine the prerequisite about
Spatial distribution randomness. Two common methods for this analysis
are Ripley's K function and DBSCAN.

\begin{itemize}
\tightlist
\item
  Ripley's K function is adopted at quantifying spatial dependence over
  various scales, offering insights into how spatial processes change
  with distance. It excels in identifying spatial patterns at specific
  scales but requires careful handling of distance scales and edge
  effects.
\item
  On the other hand, DBSCAN (Density-Based Spatial Clustering of
  Applications with Noise) is a density-based clustering algorithm that
  identifies high-density regions as clusters while marking noise or
  isolated points. This method is particularly effective for complex or
  non-homogeneous spatial distributions due to its sensitivity to
  high-density areas and robustness against noise.While DBSCAN is
  sensitive to parameter settings, once the appropriate parameters are
  chosen, it can effectively highlight distinct clustering patterns in a
  more intuitive and easily interpretable manner.
\end{itemize}

Therefore, DBSCAN may be preferred in scenarios involving distinct
clusters, irregular distributions, or significant noise in spatial data.

Before proceeding with the DBSCAN clustering analysis, I first utilize
the KNNdistplot (k-nearest neighbors distance plot), which is extremely
crucial for determining the parameters for the DBSCAN clustering
algorithm, especially the eps and minPts parameters. The KNNdistplot
could identify the density distribution among data points, thereby
xxxxxxxxxxxxx. Based on this plot, I can select an appropriate eps
value, which represents the maximum distance for points to be considered
as neighbors, and moving on to the DBSCAN for clustering analysis.

``在进行聚类分析之前，我首先利用KNNdistplot（k-最近邻距离图）来计算
\_\_\_\_\_\_\_\_\_\_。这一步骤对于确定DBSCAN聚类算法的参数，特别是eps和minPts参数至关重要。KNNdistplot帮助我们识别数据点间的密度分布，从而
\_\_\_\_\_\_\_\_\_\_。根据这个图表，我可以选择一个合适的 eps
值，该值表示点被认为是彼此邻近的最大距离，以及 \_\_\_\_\_\_\_\_\_\_。''

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#create a sp object}
\NormalTok{BluePlaquesSub}\OtherTok{\textless{}{-}}\NormalTok{ BluePlaquesSub }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as}\NormalTok{(., }\StringTok{\textquotesingle{}Spatial\textquotesingle{}}\NormalTok{)}

\CommentTok{\#create a ppp object}
\NormalTok{BluePlaquesSub.ppp }\OtherTok{\textless{}{-}} \FunctionTok{ppp}\NormalTok{(}\AttributeTok{x=}\NormalTok{BluePlaquesSub}\SpecialCharTok{@}\NormalTok{coords[,}\DecValTok{1}\NormalTok{],}
                          \AttributeTok{y=}\NormalTok{BluePlaquesSub}\SpecialCharTok{@}\NormalTok{coords[,}\DecValTok{2}\NormalTok{],}
                          \AttributeTok{window=}\NormalTok{window)}

\CommentTok{\#first extract the points from the spatial points data frame}
\NormalTok{PointsdataSub }\OtherTok{\textless{}{-}}\NormalTok{ Pointsdata }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{coordinates}\NormalTok{(.)}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.data.frame}\NormalTok{()}

\CommentTok{\# check and find the proper eps and minpts by using kNNdistplot}
\NormalTok{BluePlaquesSubPoints}\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dbscan}\SpecialCharTok{::}\FunctionTok{kNNdistplot}\NormalTok{(.,}\AttributeTok{k=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

After conducting the DBSCAN clustering analysis, the results indicate
xxxxxxxxxxxxxxxxxx, revealing spatial clustering patterns in the data.
Each cluster represents xxxxxxxxxxxxxxxxxxxxx, while noise points
(points not assigned to any cluster) may suggest xxxxxxxxxxxxxxxxxxx.
These clusters help us identify xxxxxxxxxxxxxxxxxxxx, such as
concentrated trends or anomaly patterns in specific areas.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#now run the DBSCAN analysis}
\NormalTok{DBSCANoutput }\OtherTok{\textless{}{-}}\NormalTok{ PointsdataSub }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  fpc}\SpecialCharTok{::}\FunctionTok{dbscan}\NormalTok{(.,}\AttributeTok{eps =} \DecValTok{700}\NormalTok{, }\AttributeTok{MinPts =} \DecValTok{4}\NormalTok{)}

\CommentTok{\#now plot the results}
\FunctionTok{plot}\NormalTok{(DBSCANoutput, PointsdataSub, }\AttributeTok{main =} \StringTok{"DBSCAN Output"}\NormalTok{, }\AttributeTok{frame =}\NormalTok{ F)}
\FunctionTok{plot}\NormalTok{(BoroughMap}\SpecialCharTok{$}\NormalTok{geometry, }\AttributeTok{add=}\NormalTok{T)}

\CommentTok{\# add the DBSCAN result back to dataframe}
\NormalTok{Pointsdata}\OtherTok{\textless{}{-}}\NormalTok{ PointsdataSub }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{dbcluster=}\NormalTok{DBSCANoutput}\SpecialCharTok{$}\NormalTok{cluster)}

\CommentTok{\#create some convex hull polygons to wrap around the points in our clusters}
\NormalTok{chulls }\OtherTok{\textless{}{-}}\NormalTok{ PointsdataSub }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(dbcluster) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}\AttributeTok{hull =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{n}\NormalTok{(),}
  \AttributeTok{hull =} \FunctionTok{factor}\NormalTok{(hull, }\FunctionTok{chull}\NormalTok{(coords.x1, coords.x2)))}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(hull)}

\CommentTok{\#drop the cluster =0 out from the dataframe}
\NormalTok{chulls }\OtherTok{\textless{}{-}}\NormalTok{ chulls }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(dbcluster }\SpecialCharTok{\textgreater{}=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#create a ggplot2 object from our data}
\NormalTok{dboutput\_plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data=}\NormalTok{PointsdataSub, }
                 \FunctionTok{aes}\NormalTok{(coords.x1,coords.x2, }\AttributeTok{colour=}\NormalTok{dbcluster, }\AttributeTok{fill=}\NormalTok{dbcluster)) }
\CommentTok{\#add the points in}
\NormalTok{dboutput\_plot }\OtherTok{\textless{}{-}}\NormalTok{ dboutput\_plot }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()}
\CommentTok{\#now the convex hulls}
\NormalTok{dboutput\_plot }\OtherTok{\textless{}{-}}\NormalTok{ dboutput\_plot }\SpecialCharTok{+} \FunctionTok{geom\_polygon}\NormalTok{(}\AttributeTok{data =}\NormalTok{ chulls, }
                                \FunctionTok{aes}\NormalTok{(coords.x1,coords.x2, }\AttributeTok{group=}\NormalTok{dbcluster), }
                                \AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }
\CommentTok{\#now plot, setting the coordinates to scale correctly and as a black and white plot }
\CommentTok{\#(just for the hell of it)...}
\NormalTok{dbplot }\SpecialCharTok{+} \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{coord\_equal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#add a basemap}
\DocumentationTok{\#\#First get the bbox in lat long for Harrow}
\NormalTok{HarrowWGSbb }\OtherTok{\textless{}{-}}\NormalTok{ Harrow }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_transform}\NormalTok{(., }\DecValTok{4326}\NormalTok{)}\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_bbox}\NormalTok{()}

\FunctionTok{library}\NormalTok{(OpenStreetMap)}
\CommentTok{\# create  a basemap}
\NormalTok{basemap }\OtherTok{\textless{}{-}}\NormalTok{ OpenStreetMap}\SpecialCharTok{::}\FunctionTok{openmap}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{51.5549876}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{0.4040502}\NormalTok{),}\FunctionTok{c}\NormalTok{(}\FloatTok{51.6405356}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{0.2671315}\NormalTok{),}
                         \AttributeTok{zoom=}\ConstantTok{NULL}\NormalTok{,}
                         \StringTok{"osm"}\NormalTok{)}

\CommentTok{\# convert the basemap to British National Grid}
\NormalTok{basemap\_bng }\OtherTok{\textless{}{-}} \FunctionTok{openproj}\NormalTok{(basemap, }\AttributeTok{projection=}\StringTok{"+init=epsg:27700"}\NormalTok{)}

\CommentTok{\#autoplot(basemap\_bng) sometimes works}
\FunctionTok{autoplot.OpenStreetMap}\NormalTok{(basemap\_bng)}\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data=}\NormalTok{BluePlaquesSubPoints, }
             \FunctionTok{aes}\NormalTok{(coords.x1,coords.x2, }
                 \AttributeTok{colour=}\NormalTok{dbcluster, }
                 \AttributeTok{fill=}\NormalTok{dbcluster)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_polygon}\NormalTok{(}\AttributeTok{data =}\NormalTok{ chulls, }
               \FunctionTok{aes}\NormalTok{(coords.x1,coords.x2, }
                   \AttributeTok{group=}\NormalTok{dbcluster,}
                   \AttributeTok{fill=}\NormalTok{dbcluster), }
               \AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

Additionally, the characteristics and locations of these clusters can be
used for xxxxxxxxxxxxxxxxxxx, providing crucial insights for a deeper
understanding of potential geographic phenomena in the study area.

\hypertarget{spatial-autocorrelation-ux7a7aux95f4ux81eaux76f8ux5173ux6027}{%
\subsection{Spatial Autocorrelation
空间自相关性}\label{spatial-autocorrelation-ux7a7aux95f4ux81eaux76f8ux5173ux6027}}

\begin{itemize}
\tightlist
\item
  Until now, I have checked the first prerequisite and prove that Data
  points' distribution do have certain patterns according to
  geographical information.
\item
  The next step is to examine do data points' some columns(values) also
  have their special coorelation with geographical features?
\end{itemize}

The spatial autocorrelation analysis indicates whether the spatial
distribution of variables is random or exhibits spatial dependency. This
is crucial for xxxxxxxxxx, as it helps in ensuring the accuracy and
validity of the spatial regression model.

\hypertarget{which-method-for-spatial-autocorrelation}{%
\subsubsection{Which method for spatial
autocorrelation?}\label{which-method-for-spatial-autocorrelation}}

There are several spatial autocorrelation methods such as Global Moran's
I\citep{moran_notes_1950}, Local Moran's I\citep{anselin_local_1995},
Geary's C\citep{geary_contiguity_1954}, and
Getis-Ord\citep{ord_local_1995}. And I believe most suitable method
depends on the comparing process between research objectives and
methods' principles, advantages/disadvantages and applicability.

The local Moran's I and Getis-Ord are usually more adaptable to some
local analysis, easier to identify local hotspots, coldspots, or spatial
anomalies\citep{abdulhafedh_novel_2017}. While my research goal at this
step is to examine the existence of spatial autocorrelation in a global
view, plus that Geary's C focuses more on measuring similarity between
values in neighboring areas. Therefore, I choose Global Moran's I for
the spaital autocorrelation analysis.

\hypertarget{which-method-for-spatial-autocorrelation-1}{%
\subsubsection{Which method for spatial
autocorrelation?}\label{which-method-for-spatial-autocorrelation-1}}

Before performing spatial autocorrelation regression analysis,
constructing a weight matrix is a prerequisite. The weight matrix, which
represents xxxxxxx, allows us to xxxxxxxx. From this matrix, we can
infer xxxxxxxxx, which is instrumental in understanding the spatial
relationships among the observations.''

The interpretation of spatial autocorrelation regression analysis
involves xxxxxxxxxxxxx. Key metrics such as Moran's I or Geary's C
indicate xxxxxxxxxxx. These results are significant for xxxxxxxxxxxx, as
they provide insights into the spatial dependence and help in
xxxxxxxxxxxx.

This could be very important for selecting the proper regression model,
about whether we should take the spatial features into consideration in
regression model.

\hypertarget{variables-selection-ux7279ux5f81ux9009ux62e9ux4e0eux5de5ux7a0b}{%
\section{Variables Selection
特征选择与工程}\label{variables-selection-ux7279ux5f81ux9009ux62e9ux4e0eux5de5ux7a0b}}

\hypertarget{selecting-independent-variables-based-on-esda-and-research-question}{%
\subsection{Selecting Independent Variables based on ESDA and Research
Question}\label{selecting-independent-variables-based-on-esda-and-research-question}}

统计方法：例如使用相关系数或卡方检验来识别与目标变量最相关的特征。
模型基方法：如使用随机森林或LASSO回归进行特征重要性评估。
递归特征消除：这是一种利用模型精度来选择特征的方法。
特征工程：转换和创建新特征来改善模型的性能。常见的做法包括：

\hypertarget{data-normalization-and-standardlization-ux6570ux636eux89c4ux8303ux5316ux4e0eux6807ux51c6ux5316}{%
\subsection{DATA Normalization and Standardlization
数据规范化与标准化}\label{data-normalization-and-standardlization-ux6570ux636eux89c4ux8303ux5316ux4e0eux6807ux51c6ux5316}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 数据规范化}
\NormalTok{normalize }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
  \FunctionTok{return}\NormalTok{ ((x }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(x)) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{max}\NormalTok{(x) }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(x)))}
\NormalTok{\}}

\NormalTok{DATA\_normalized }\OtherTok{\textless{}{-}} \FunctionTok{as.DATA.frame}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(DATA, normalize))}

\CommentTok{\#   2. 标准化（Standardization）}
\CommentTok{\#标准化指的是将数据转换为均值为0，标准差为1的分布。这通过从每个观测中减去均值并除以标准差来实现}
\NormalTok{DATA\_standardized }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(DATA)}
\CommentTok{\#scale(x, center = TRUE, scale = TRUE)}
\CommentTok{\#x 是要进行标准化的数据。}
\CommentTok{\#center = TRUE 表示数据会先减去它的均值。}
\CommentTok{\#scale = TRUE 表示数据会除以它的标准差。}

\CommentTok{\#caret 包提供了更多高级的预处理功能。}
\CommentTok{\#使用 preProcess 函数进行规范化。}
\FunctionTok{library}\NormalTok{(caret)}

\NormalTok{preProcValues }\OtherTok{\textless{}{-}} \FunctionTok{preProcess}\NormalTok{(DATA, }\AttributeTok{method =} \FunctionTok{c}\NormalTok{(}\StringTok{"range"}\NormalTok{))}
\NormalTok{preProcValues }\OtherTok{\textless{}{-}} \FunctionTok{preProcess}\NormalTok{(DATA, }\AttributeTok{method =} \FunctionTok{c}\NormalTok{(}\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{))}
\NormalTok{DATA\_normalized }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(preProcValues, DATA)}
\CommentTok{\#preProcess(x, method)}
\CommentTok{\#x 是要处理的数据。}
\CommentTok{\#method = c("range") 指定使用范围规范化。}
\CommentTok{\#method = c("center", "scale") 指定使用数据中心化和标准化。}

\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(purrr)}

\NormalTok{DATA\_normalized }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, normalize)}

\NormalTok{DATA\_standardized }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, scale)}
\end{Highlighting}
\end{Shaded}

\hypertarget{create-variables-for-generalising-several-similar-columnsux57faux4e8eux73b0ux6709ux7279ux5f81ux521bux5efaux65b0ux7279ux5f81}{%
\subsection{Create Variables for Generalising several similar
columns基于现有特征创建新特征}\label{create-variables-for-generalising-several-similar-columnsux57faux4e8eux73b0ux6709ux7279ux5f81ux521bux5efaux65b0ux7279ux5f81}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#   1. 基本计算}
\CommentTok{\#可以直接使用 R 的基础算术运算符（如 +, {-}, *, /）来创建新变量。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{new\_var }\OtherTok{=}\NormalTok{ DATA}\SpecialCharTok{$}\NormalTok{var1 }\SpecialCharTok{+}\NormalTok{ DATA}\SpecialCharTok{$}\NormalTok{var2}

\CommentTok{\#   2. 使用 dplyr 的 mutate 函数}
\CommentTok{\#dplyr 包的 mutate 函数非常适合在数据框中添加新列或修改现有列。}
\FunctionTok{library}\NormalTok{(dplyr)}
\NormalTok{DATA }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{new\_var =}\NormalTok{ var1 }\SpecialCharTok{/}\NormalTok{ var2)}

\CommentTok{\#   3. 条件语句}
\CommentTok{\#使用 ifelse 函数或 dplyr 的 case\_when 函数基于条件创建新变量。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{new\_var }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{var1 }\SpecialCharTok{\textgreater{}}\NormalTok{ threshold, value\_if\_true, value\_if\_false)}

\NormalTok{DATA }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{new\_var =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{  condition1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ value1,}
\NormalTok{  condition2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ value2,}
  \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}}\NormalTok{ default\_value}
\NormalTok{))}

\CommentTok{\#   4. 日期和时间变量}
\CommentTok{\#使用 lubridate 包来处理和创建基于日期和时间的派生变量。}

\FunctionTok{library}\NormalTok{(lubridate)}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{year }\OtherTok{\textless{}{-}} \FunctionTok{year}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{date\_var)}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{month }\OtherTok{\textless{}{-}} \FunctionTok{month}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{date\_var)}

\CommentTok{\#   5. 文本处理}
\CommentTok{\#使用 stringr 包处理字符串数据，创建基于文本的派生变量。}
\FunctionTok{library}\NormalTok{(stringr)}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{new\_var }\OtherTok{=} \FunctionTok{str\_sub}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{text\_var, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{\# 提取字符串前五个字符}

\CommentTok{\#   6. 分类变量编码}
\CommentTok{\#使用 factor 或 dplyr 的 mutate 与 as.factor 来创建或修改分类变量}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{new\_var }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{var1)}
\NormalTok{DATA }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{new\_var =} \FunctionTok{as.factor}\NormalTok{(var1))}

\CommentTok{\#   7. 数值转换和标准化}
\CommentTok{\#使用 scale 函数对数值变量进行标准化。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{new\_var }\OtherTok{=} \FunctionTok{scale}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{var1, }\AttributeTok{center =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\#   8. 汇总统计}
\CommentTok{\#使用 dplyr 的 group\_by 和 summarize 来创建基于组的派生变量。}
\NormalTok{DATA\_summary }\OtherTok{\textless{}{-}}\NormalTok{ DATA }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(group\_var) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_var =} \FunctionTok{mean}\NormalTok{(var1, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}

\CommentTok{\#   9. 使用数学和统计函数}
\CommentTok{\#R 提供了大量的数学和统计函数，如 log, exp, mean, median 等。}
\NormalTok{DATA}\SpecialCharTok{$}\NormalTok{log\_var }\OtherTok{=} \FunctionTok{log}\NormalTok{(DATA}\SpecialCharTok{$}\NormalTok{var1)}
\end{Highlighting}
\end{Shaded}

\hypertarget{regression-modelling-ux5efaux7acbux6a21ux578b}{%
\section{Regression Modelling
建立模型}\label{regression-modelling-ux5efaux7acbux6a21ux578b}}

\hypertarget{spatial-baseline-modelux5efaux7acbux7a7aux95f4ux57faux7ebfux6a21ux578b}{%
\subsection{Spatial Baseline
Model建立空间基线模型}\label{spatial-baseline-modelux5efaux7acbux7a7aux95f4ux57faux7ebfux6a21ux578b}}

Establishing a spatial baseline model typically refers to creating a
basic regression model that accounts for spatial variability. This model
serves as a benchmark for comparison, allowing the evaluation of the GWR
model or other spatial models against non-spatial models, like ordinary
least squares regression. The spatial baseline model usually includes
variables relevant to the study but does not incorporate treatments for
spatial variability, thus providing a clear view of the model's
performance changes after introducing the spatial dimension.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 在深入调整模型之前，建立一个空间基线模型，以了解空间变量对因变量的基本影响}
\end{Highlighting}
\end{Shaded}

\hypertarget{training-set-and-testing-set-ux6570ux636eux5206ux5272}{%
\subsection{Training set and Testing set
数据分割}\label{training-set-and-testing-set-ux6570ux636eux5206ux5272}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#如果适用，将数据分割为训练集和测试集，考虑到空间数据的特殊性。}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-applying}{%
\subsection{Model Applying}\label{model-applying}}

\hypertarget{ux6a21ux578bux8bc4ux4f30ux4e0eux8c03ux6574}{%
\section{模型评估与调整}\label{ux6a21ux578bux8bc4ux4f30ux4e0eux8c03ux6574}}

\hypertarget{ux4ea4ux53c9ux9a8cux8bc1}{%
\subsection{交叉验证}\label{ux4ea4ux53c9ux9a8cux8bc1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 使用K折交叉验证来评估模型性能的稳定性。 性能指标：如均方误差（MSE）、决定系数（R²）等。}
\end{Highlighting}
\end{Shaded}

\hypertarget{ux8c03ux6574ux8d85ux53c2ux6570}{%
\subsection{调整超参数}\label{ux8c03ux6574ux8d85ux53c2ux6570}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#使用网格搜索（Grid Search）或随机搜索（Random Search）来找到最佳参数。}
\end{Highlighting}
\end{Shaded}

\hypertarget{residuals-analysis-ux6b8bux5deeux5206ux6790}{%
\subsection{Residuals Analysis
残差分析}\label{residuals-analysis-ux6b8bux5deeux5206ux6790}}

In spatial regression models, ensuring that residuals are normally
distributed is important because many statistical inferences (like tests
for the significance of parameters) are based on the assumption of
normality. If residuals are not normally distributed, this can affect
the reliability of the model and the validity of the conclusions.
Therefore, using a Q-Q plot to examine the normality of residuals in
spatial regression models is a crucial step in model diagnostics.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#  A Q{-}Q plot is a common method to check if data follows a normal distribution. In a Q{-}Q plot of a standard normal distribution, if the data points roughly fall along a straight line, it suggests that the data are approximately normally distributed.}
\CommentTok{\# Identifying Outliers: The Q{-}Q plot can also help identify outliers in the data. Data points that deviate significantly from the line may indicate outliers.}

\CommentTok{\# Create the dataframe for normal distribution reference}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{) }\CommentTok{\# using the normal distribution random generated numbers.}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ data)}

\FunctionTok{ggplot}\NormalTok{(df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ sample)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{col =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Q{-}Q Plot"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Theoretical Quantiles"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Sample Quantiles"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{section}{%
\subsubsection{}\label{section}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#特别在回归模型中，检查残差是否呈现随机分布。 }
\end{Highlighting}
\end{Shaded}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

\hypertarget{summary}{%
\subsection{Summary}\label{summary}}

\hypertarget{research-limitation}{%
\subsection{Research Limitation}\label{research-limitation}}

\hypertarget{future-research}{%
\subsection{Future Research}\label{future-research}}

\begin{itemize}
\tightlist
\item
  Geography Detector 地理探测器
\item
\end{itemize}

  \bibliography{reference\_V0.bib}

\end{document}
